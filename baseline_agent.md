# Baseline Agent åˆ†ææŠ¥å‘Š

## æ¦‚è¿°

`baseline_agent.py` å®ç°äº†ä¸€ä¸ªåŸºäºè§†è§‰çš„äººä½“è·Ÿè¸ªagentï¼Œä½¿ç”¨PDæ§åˆ¶å™¨æ ¹æ®ç›®æ ‡äººç‰©åœ¨ç”»é¢ä¸­çš„ä½ç½®å’Œå¤§å°æ¥æ§åˆ¶æœºå™¨äººç§»åŠ¨ã€‚

---

## æ–‡ä»¶ç»“æ„

```
baseline_agent.py
â”œâ”€â”€ evaluate_agent()      # ä¸»è¯„ä¼°å¾ªç¯
â””â”€â”€ class GTBBoxAgent     # åŸºäºBBoxçš„è·Ÿè¸ªæ§åˆ¶å™¨
    â”œâ”€â”€ __init__()        # åˆå§‹åŒ–PDå‚æ•°
    â”œâ”€â”€ reset()           # é‡ç½®çŠ¶æ€ï¼Œä¿å­˜è§†é¢‘
    â””â”€â”€ act()             # æ ¸å¿ƒæ§åˆ¶é€»è¾‘
```

---

## æ ¸å¿ƒä»£ç åˆ†æ

### 1. PDæ§åˆ¶å™¨å‚æ•°åˆå§‹åŒ–

```python
class GTBBoxAgent(AgentConfig):
    def __init__(self, result_path, target_id=None):
        super().__init__()
        print("Initialize gtbbox agent")

        self.result_path = result_path
        os.makedirs(self.result_path, exist_ok=True)
        self.target_id = target_id
        
        self.rgb_list = []
        self.rgb_box_list = []

        # PDæ§åˆ¶å™¨å‚æ•°
        self.kp_t = 2      # è½¬å‘æ¯”ä¾‹å¢ç›Šï¼ˆæ§åˆ¶yawï¼‰
        self.kd_t = 0      # è½¬å‘å¾®åˆ†å¢ç›Š
        self.kp_f = 1      # å‰è¿›æ¯”ä¾‹å¢ç›Šï¼ˆæ§åˆ¶å‰è¿›é€Ÿåº¦ï¼‰
        self.kd_f = 0      # å‰è¿›å¾®åˆ†å¢ç›Š
        self.kp_y = 0.5    # ä¾§ç§»æ¯”ä¾‹å¢ç›Š
        self.kd_y = 0      # ä¾§ç§»å¾®åˆ†å¢ç›Š

        self.prev_error_t = 0  # ä¸Šä¸€å¸§è½¬å‘è¯¯å·®
        self.prev_error_f = 0  # ä¸Šä¸€å¸§å‰è¿›è¯¯å·®

        self.first_inside = True
        self.reset()
```

**é—®é¢˜**ï¼š`kd_t = 0` å’Œ `kd_f = 0`ï¼Œå¾®åˆ†é¡¹å®Œå…¨æ²¡ç”¨ï¼Œè¿™æ˜¯ä¸ªçº¯Pæ§åˆ¶å™¨ï¼Œæ²¡æœ‰é˜»å°¼ï¼Œå®¹æ˜“éœ‡è¡å’Œè¶…è°ƒã€‚

---

### 2. æ ¸å¿ƒæ§åˆ¶é€»è¾‘ `act()`

```python
def act(self, observations, detector, episode_id):
    self.episode_id = episode_id
    
    rgb = observations["agent_1_articulated_agent_jaw_rgb"]
    rgb_ = rgb[:, :, :3]
    image = np.asarray(rgb_[:, :, ::-1])
    height, width = image.shape[:2]
    
    action = [0, 0, 0]  # é»˜è®¤åŠ¨ä½œï¼šä¸åŠ¨

    target_tracked = False
    
    # æ–¹å¼1ï¼šå¦‚æœæŒ‡å®šäº†target_idï¼Œä½¿ç”¨panopticåˆ†å‰²
    if self.target_id is not None and "agent_1_articulated_agent_jaw_panoptic" in observations:
        panoptic = observations["agent_1_articulated_agent_jaw_panoptic"]
        target_mask = (panoptic == self.target_id)
        if hasattr(target_mask, "ndim") and target_mask.ndim == 3:
            target_mask = target_mask[:, :, 0]
        if np.any(target_mask):
            # ä»maskè®¡ç®—bounding box
            rows = np.any(target_mask, axis=1)
            cols = np.any(target_mask, axis=0)
            r_idx = np.where(rows)[0]
            c_idx = np.where(cols)[0]
            rmin, rmax = int(r_idx[0]), int(r_idx[-1])
            cmin, cmax = int(c_idx[0]), int(c_idx[-1])
            box = np.array([cmin, rmin, cmax, rmax], dtype=np.float32)
            
            # å½’ä¸€åŒ–box: [center_x, center_y, width, height]
            best_box = np.array([
                (box[0] + box[2]) / (2 * width),
                (box[1] + box[3]) / (2 * height),
                (box[2] - box[0]) / width,
                (box[3] - box[1]) / height,
            ], dtype=np.float32)

            # è®¡ç®—æ§åˆ¶è¯¯å·®
            center_x = best_box[0]
            error_t = 0.5 - center_x  # è½¬å‘è¯¯å·®ï¼šè®©äººä¿æŒåœ¨ç”»é¢ä¸­å¿ƒ
            
            bbox_area = (box[2] - box[0]) * (box[3] - box[1])
            error_f = (30000 - bbox_area) / 10000  # å‰è¿›è¯¯å·®ï¼šç”¨bboxé¢ç§¯ä¼°è®¡è·ç¦»
            if abs(error_f) < 0.5:
                error_f = 0  # æ­»åŒº

            # PDæ§åˆ¶
            derivative_t = error_t - self.prev_error_t
            derivative_f = error_f - self.prev_error_f

            yaw_speed = self.kp_t * error_t + self.kd_t * derivative_t   # = 2 * error_t
            move_speed = self.kp_f * error_f + self.kd_f * derivative_f  # = 1 * error_f
            y_speed = self.kp_y * error_t + self.kd_y * derivative_t     # = 0.5 * error_t

            self.prev_error_t = error_t
            self.prev_error_f = error_f

            action = [move_speed, y_speed, yaw_speed]
            target_tracked = True

    # æ–¹å¼2ï¼šä½¿ç”¨detectoræä¾›çš„ä¸»è¦äººç‰©bbox
    if not target_tracked:
        if detector['agent_1_main_humanoid_detector_sensor']['facing']:
            box = detector['agent_1_main_humanoid_detector_sensor']['box']
            best_box = np.array([
                (box[0]+box[2])/(2*width), 
                (box[1]+box[3])/(2*height), 
                (box[2]-box[0])/width, 
                (box[3]-box[1])/height
            ], dtype=np.float32)
            
            center_x = best_box[0]
            error_t = 0.5 - center_x
            error_f = (30000 - (box[2]-box[0])*(box[3]-box[1])) / 10000
            if abs(error_f) < 0.5:
                error_f = 0

            derivative_t = error_t - self.prev_error_t
            derivative_f = error_f - self.prev_error_f

            yaw_speed = self.kp_t * error_t + self.kd_t * derivative_t
            move_speed = self.kp_f * error_f + self.kd_f * derivative_f
            y_speed = self.kp_y * error_t + self.kd_y * derivative_t

            self.prev_error_t = error_t
            self.prev_error_f = error_f

            action = [move_speed, y_speed, yaw_speed]
        else:
            action = [0, 0, 0]  # çœ‹ä¸åˆ°äººå°±åœä¸‹
    
    self.last_action = action
    self.rgb_list.append(rgb_)

    return action
```

---

### 3. è¯„ä¼°å¾ªç¯ä¸å¤±è´¥æ£€æµ‹

```python
def evaluate_agent(config, dataset_split, save_path, target_id=None) -> None:
    robot_config = GTBBoxAgent(save_path, target_id)
    with habitat.TrackEnv(config=config, dataset=dataset_split) as env:
        sim = env.sim
        robot_config.reset()
        
        num_episodes = len(env.episodes)
        for _ in trange(num_episodes):
            obs = env.reset()
            # ... å…‰ç…§è®¾ç½®çœç•¥ ...

            result = {}
            record_infos = []
            
            humanoid_agent_main = sim.agents_mgr[0].articulated_agent
            robot_agent = sim.agents_mgr[1].articulated_agent

            iter_step = 0
            followed_step = 0
            too_far_count = 0
            status = 'Normal'

            while not env.episode_over:
                record_info = {}
                obs = sim.get_sensor_observations()
                detector = env.task._get_observations(env.current_episode)
                action = robot_config.act(obs, detector, env.current_episode.episode_id)

                action_dict = {
                    "action": ("agent_0_humanoid_navigate_action", "agent_1_base_velocity", ...),
                    "action_args": {"agent_1_base_vel": action}
                }
                
                iter_step += 1
                env.step(action_dict)

                info = env.get_metrics()
                if info['human_following'] == 1.0:
                    print("Followed")
                    followed_step += 1
                    too_far_count = 0
                else:
                    print("Lost")

                # å¤±è´¥æ¡ä»¶1ï¼šè·ç¦»è¶…è¿‡4ç±³æŒç»­20æ­¥
                if np.linalg.norm(robot_agent.base_pos - humanoid_agent_main.base_pos) > 4.0:
                    too_far_count += 1
                    if too_far_count > 20:
                        print("Too far from human!")
                        status = 'Lost'
                        finished = False
                        break

                # è®°å½•ä¿¡æ¯
                record_info["step"] = iter_step
                record_info["dis_to_human"] = float(np.linalg.norm(robot_agent.base_pos - humanoid_agent_main.base_pos))
                record_info["facing"] = info['human_following']
                record_info["base_velocity"] = action
                record_infos.append(record_info)

                # å¤±è´¥æ¡ä»¶2ï¼šç¢°æ’
                if info['human_collision'] == 1.0:
                    print("Collision detected!")
                    status = 'Collision'
                    finished = False
                    break
```

---

### 4. æˆåŠŸåˆ¤å®šä¸æ•°æ®ä¿å­˜

```python
            # æˆåŠŸåˆ¤å®šé€»è¾‘
            if env.episode_over:
                finished = True

            result['finish'] = finished
            result['status'] = status
            
            # å…³é”®ï¼šæˆåŠŸåˆ¤å®š
            if iter_step < 300:
                result['success'] = info['human_following_success'] and info['human_following']
            else:
                result['success'] = info['human_following']
            
            result['following_rate'] = followed_step / iter_step
            result['following_step'] = followed_step
            result['total_step'] = iter_step
            result['collision'] = info['human_collision']

            # åªæœ‰æˆåŠŸæ‰ä¿å­˜æ•°æ®ï¼
            if result['success']:
                scene_key = osp.splitext(osp.basename(env.current_episode.scene_id))[0].split('.')[0]
                save_dir = os.path.join(save_path, scene_key)
                os.makedirs(save_dir, exist_ok=True)
                
                # ä¿å­˜è½¨è¿¹ä¿¡æ¯
                with open(os.path.join(save_dir, "{}_info.json".format(env.current_episode.episode_id)), "w") as f:
                    json.dump(record_infos, f, indent=2)
                
                # ä¿å­˜ç»“æœæ‘˜è¦
                with open(os.path.join(save_dir, "{}.json".format(env.current_episode.episode_id)), "w") as f:
                    json.dump(result, f, indent=2)

            # é‡ç½®agentï¼ŒæˆåŠŸæ—¶ä¿å­˜è§†é¢‘
            robot_config.reset(env.current_episode, success=result['success'])
```

---

### 5. è§†é¢‘ä¿å­˜é€»è¾‘

```python
def reset(self, episode: NavigationEpisode = None, success: bool = False):
    if len(self.rgb_list) != 0 and episode is not None:
        if success:
            scene_key = osp.splitext(osp.basename(episode.scene_id))[0].split('.')[0]
            save_dir = os.path.join(self.result_path, scene_key)
            os.makedirs(save_dir, exist_ok=True)
            output_video_path = os.path.join(save_dir, "{}.mp4".format(episode.episode_id))
            imageio.mimsave(output_video_path, self.rgb_list)
            print(f"Successfully saved the episode video with episode id {episode.episode_id}")
        self.rgb_list = []  # æ¸…ç©ºï¼Œä¸ç®¡æˆåŠŸä¸å¦
    
    self.first_inside = True
```

---

## è‡´å‘½é—®é¢˜åˆ†æ

### é—®é¢˜1ï¼šç”¨bboxé¢ç§¯ä¼°è®¡è·ç¦» â€” æ ¹æœ¬æ€§é”™è¯¯

```python
bbox_area = (box[2] - box[0]) * (box[3] - box[1])
error_f = (30000 - bbox_area) / 10000
```

**å‡è®¾**ï¼š`bboxé¢ç§¯å° = äººè¿œï¼Œé¢ç§¯å¤§ = äººè¿‘`

**ç°å®**ï¼šbboxé¢ç§¯å—å¤šç§å› ç´ å½±å“ï¼Œä¸å®é™…è·ç¦»ä¸æ˜¯ç®€å•çš„åæ¯”å…³ç³»ï¼š

| æƒ…å†µ | bboxé¢ç§¯ | å®é™…è·ç¦» | æ§åˆ¶ç»“æœ |
|------|----------|----------|----------|
| äººåœ¨ç”»é¢ä¸­å¤®æ­£å¯¹ | å¤§ | è¿‘ | âœ… æ­£ç¡®å‡é€Ÿ |
| äººåœ¨ç”»é¢è¾¹ç¼˜ | å° | è¿‘ | âŒ é”™è¯¯åŠ é€Ÿ |
| äººè¢«éƒ¨åˆ†é®æŒ¡ | å° | è¿‘ | âŒ é”™è¯¯åŠ é€Ÿ |
| äººä¾§èº« | å° | ä¸­ | âŒ é”™è¯¯åŠ é€Ÿ |
| äººå¼¯è…° | å˜åŒ– | ä¸å˜ | âŒ é€Ÿåº¦éœ‡è¡ |

**å®æµ‹åæœ**ï¼š
```
Step 12: action=[3.0, 0.25, 1.0] dis=1.27m â†’ Followed
Step 13: action=[3.0, 0.25, 1.0] dis=0.91m â†’ Collision!
```

è·ç¦»ä»…0.91ç±³æ—¶ï¼Œbboxå¯èƒ½åªæœ‰å‡ åƒåƒç´ ï¼Œ`error_f â‰ˆ 3.0`ï¼Œagentä»¥æœ€å¤§é€Ÿåº¦å‰å†² â†’ **ç¢°æ’**

---

### é—®é¢˜2ï¼šæ²¡æœ‰é€Ÿåº¦é™åˆ¶

```python
move_speed = self.kp_f * error_f  # kp_f = 1, æ— ä¸Šé™ï¼
```

å½“ `bbox_area = 0`ï¼ˆå®Œå…¨çœ‹ä¸åˆ°æˆ–é¢ç§¯æå°ï¼‰æ—¶ï¼š
```python
error_f = (30000 - 0) / 10000 = 3.0
move_speed = 1 * 3.0 = 3.0  # å…¨é€Ÿå‰è¿›ï¼
```

æ²¡æœ‰ä»»ä½• `clamp` æˆ–é€Ÿåº¦ä¸Šé™ã€‚

---

### é—®é¢˜3ï¼šæ²¡æœ‰å®‰å…¨è·ç¦»é˜ˆå€¼

ä»£ç ä¸­å®Œå…¨æ²¡æœ‰åŸºäº**å®é™…è·ç¦»**çš„å®‰å…¨æœºåˆ¶ï¼š

```python
# åº”è¯¥æœ‰ä½†æ²¡æœ‰çš„é€»è¾‘ï¼š
if actual_distance < 1.0:
    move_speed = 0  # å¤ªè¿‘äº†ï¼Œåœä¸‹ï¼
```

ä»…ä¾èµ–ä¸å¯é çš„bboxé¢ç§¯ä¼°è®¡ï¼Œæ²¡æœ‰ä½¿ç”¨ç¯å¢ƒä¸­å¯ç”¨çš„ï¼š
- æ·±åº¦ä¼ æ„Ÿå™¨
- çœŸå®è·ç¦»ï¼ˆ`np.linalg.norm(robot_agent.base_pos - humanoid_agent_main.base_pos)`ï¼Œä»…ç”¨äºæ—¥å¿—ï¼‰

---

### é—®é¢˜4ï¼šLostçŠ¶æ€å¤„ç†è¿‡äºç®€é™‹

```python
if not detector['agent_1_main_humanoid_detector_sensor']['facing']:
    action = [0, 0, 0]  # å®Œå…¨åœæ­¢ï¼Œä»€ä¹ˆéƒ½ä¸åš
```

çœ‹ä¸åˆ°äººå°±å®Œå…¨åœæ­¢ï¼Œæ²¡æœ‰ï¼š
- æƒ¯æ€§/åŠ¨é‡è¡¥å¿
- æœç´¢æ—‹è½¬è¡Œä¸º
- å†å²è½¨è¿¹é¢„æµ‹
- æœ€åå·²çŸ¥ä½ç½®è¿½è¸ª

---

### é—®é¢˜5ï¼šåªä¿å­˜æˆåŠŸæ•°æ®

```python
if result['success']:
    # ä¿å­˜æ•°æ®
```

å¤±è´¥çš„episodeï¼ˆç¢°æ’ã€è·Ÿä¸¢ï¼‰ä¸ä¿å­˜ä»»ä½•æ•°æ®ã€‚å¦‚æœagentè¡¨ç°å¤ªå·®ï¼ˆå…¨å¤±è´¥ï¼‰ï¼Œ`save_path` ç›®å½•ä¼šæ˜¯ç©ºçš„ã€‚

---

## å®æµ‹è¡¨ç°

ä»è¿è¡Œæ—¥å¿—çœ‹ï¼Œå¤§é‡episodeå› ç¢°æ’å¤±è´¥ï¼š

| Episode | ä¸­é—´çŠ¶æ€ | ç»“å±€ | ç¢°æ’å‰è·ç¦» |
|---------|---------|------|-----------|
| ID: 0 | æœ‰Followed | Collision | 0.91m |
| ID: 2 | æœ‰Followed | Collision | 0.52m |
| ID: 15 | æœ‰Followed | Collision | 0.53m |
| ID: 27 | æœ‰Followed | Collision | 0.50m |
| ID: 3 | å…¨Lost | Too far | N/A |

**å…±åŒç‰¹å¾**ï¼š
1. èƒ½æ£€æµ‹åˆ°äººæ—¶ç–¯ç‹‚å‰è¿›
2. è¿‘è·ç¦»æ—¶bboxé¢ç§¯ä¼°è®¡å¤±æ•ˆ
3. æ²¡æœ‰å‡é€Ÿ â†’ ç›´æ¥æ’ä¸Š

---

## æ”¹è¿›å»ºè®®

### æœ€å°æ”¹åŠ¨ï¼ˆè®©å®ƒèƒ½è·‘å‡ºæ•°æ®ï¼‰

```python
def act(self, observations, detector, episode_id):
    # ... ç°æœ‰ä»£ç  ...
    
    # åœ¨è®¡ç®—å®Œ move_speed åï¼Œæ·»åŠ ï¼š
    
    # 1. é€Ÿåº¦é™åˆ¶
    move_speed = max(-1.0, min(1.0, move_speed))
    yaw_speed = max(-2.0, min(2.0, yaw_speed))
    
    # 2. è¿‘è·ç¦»å®‰å…¨é˜ˆå€¼ï¼ˆåŸºäºbboxé¢ç§¯ï¼‰
    if bbox_area > 40000:  # bboxå¾ˆå¤§è¯´æ˜å¾ˆè¿‘
        move_speed = min(move_speed, 0)  # ä¸å†å‰è¿›ï¼Œåªèƒ½åœæˆ–åé€€
    
    # 3. æˆ–è€…æ›´ä¿å®ˆï¼šbboxé¢ç§¯è¶Šå¤§ï¼Œæœ€å¤§é€Ÿåº¦è¶Šä½
    max_speed = max(0.1, (50000 - bbox_area) / 50000 * 2.0)
    move_speed = max(-max_speed, min(max_speed, move_speed))
    
    action = [move_speed, y_speed, yaw_speed]
```

### å‚æ•°è°ƒæ•´

```python
# é™ä½å‰è¿›å¢ç›Šï¼Œå‡å°‘æ¿€è¿›æ€§
self.kp_f = 0.3  # ä»1.0é™åˆ°0.3

# æé«˜ç›®æ ‡bboxé¢ç§¯é˜ˆå€¼ï¼ˆä¿æŒæ›´è¿œè·ç¦»ï¼‰
TARGET_BBOX_AREA = 50000  # ä»30000æé«˜åˆ°50000
error_f = (TARGET_BBOX_AREA - bbox_area) / 10000
```

### æ ¹æœ¬æ”¹è¿›

1. **ä½¿ç”¨æ·±åº¦ä¼ æ„Ÿå™¨**
```python
depth = observations["agent_1_articulated_agent_jaw_depth"]
# è·å–bboxåŒºåŸŸçš„å¹³å‡æ·±åº¦ä½œä¸ºè·ç¦»ä¼°è®¡
target_depth = depth[rmin:rmax, cmin:cmax].mean()
error_f = (TARGET_DISTANCE - target_depth) / SCALE
```

2. **æ·»åŠ çœŸå®è·ç¦»å®‰å…¨æ£€æŸ¥**
```python
# åœ¨evaluate_agentä¸­å·²ç»è®¡ç®—äº†çœŸå®è·ç¦»
actual_dist = np.linalg.norm(robot_agent.base_pos - humanoid_agent_main.base_pos)
if actual_dist < 1.0:
    action[0] = min(action[0], 0)  # ä¸èƒ½å†å‰è¿›
```

3. **å®ç°å‡é€Ÿæ›²çº¿**
```python
# è·ç¦»è¶Šè¿‘ï¼Œæœ€å¤§å…è®¸é€Ÿåº¦è¶Šä½
if actual_dist < 2.0:
    max_forward_speed = actual_dist * 0.5  # çº¿æ€§å‡é€Ÿ
    move_speed = min(move_speed, max_forward_speed)
```

4. **LostçŠ¶æ€æœç´¢è¡Œä¸º**
```python
if not facing:
    # ä¸æ˜¯åœä¸‹ï¼Œè€Œæ˜¯æ—‹è½¬æœç´¢
    if self.last_known_direction == 'left':
        action = [0, 0, 1.0]  # å‘å·¦è½¬
    else:
        action = [0, 0, -1.0]  # å‘å³è½¬
```

---

## æ•°æ®è¾“å‡ºæ ¼å¼

æˆåŠŸæ—¶ä¿å­˜åˆ° `{save_path}/{scene_key}/`ï¼š

1. **`{episode_id}.json`** - ç»“æœæ‘˜è¦
```json
{
  "finish": true,
  "status": "Normal",
  "success": true,
  "following_rate": 0.85,
  "following_step": 170,
  "total_step": 200,
  "collision": 0.0,
  "instruction": "Follow the person in red shirt"
}
```

2. **`{episode_id}_info.json`** - é€å¸§è½¨è¿¹
```json
[
  {"step": 1, "dis_to_human": 2.5, "facing": 1.0, "base_velocity": [0.5, 0.1, 0.2]},
  {"step": 2, "dis_to_human": 2.3, "facing": 1.0, "base_velocity": [0.4, 0.1, 0.1]},
  ...
]
```

3. **`{episode_id}.mp4`** - RGBè§†é¢‘

---

## è¯„ä»·

**å“å‘³è¯„åˆ†**ï¼šğŸ”´ åƒåœ¾

è¿™æ˜¯ä¸€ä¸ªç©å…·çº§åˆ«çš„æ§åˆ¶å™¨ã€‚æ ¸å¿ƒé—®é¢˜æ˜¯**æ•°æ®ç»“æ„é”™äº†**â€”â€”ç”¨2D bboxé¢ç§¯æ¥ä¼°è®¡3Dè·ç¦»ï¼Œè¿™ä¸ªå‡è®¾åœ¨ä»»ä½•å®é™…åœºæ™¯éƒ½ä¸æˆç«‹ã€‚

æ­£ç¡®çš„åšæ³•ï¼š
1. ç›´æ¥ç”¨æ·±åº¦ä¼ æ„Ÿå™¨è·å–è·ç¦»
2. æˆ–è€…ç”¨3Dç‚¹äº‘
3. æˆ–è€…è‡³å°‘åšä¸ªbboxé¢ç§¯åˆ°è·ç¦»çš„æ ‡å®šæ›²çº¿

è€Œä¸æ˜¯æ‹è„‘è¢‹å†™ä¸ª `(30000 - bbox_area) / 10000`ã€‚
